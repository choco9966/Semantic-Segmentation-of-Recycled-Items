{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1' # specify GPUs locally\n",
    "\n",
    "OUTPUT_DIR = './submission'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "    \n",
    "dataset_path = './data/data'\n",
    "anns_file_path = dataset_path + '/' + 'train.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import label_accuracy_score\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 전처리를 위한 라이브러리\n",
    "from pycocotools.coco import COCO\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# 시각화를 위한 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from adamp import AdamP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read annotations\n",
    "with open(anns_file_path, 'r') as f:\n",
    "    dataset = json.loads(f.read())\n",
    "\n",
    "categories = dataset['categories']\n",
    "anns = dataset['annotations']\n",
    "imgs = dataset['images']\n",
    "nr_cats = len(categories)\n",
    "nr_annotations = len(anns)\n",
    "nr_images = len(imgs)\n",
    "\n",
    "# Load categories and super categories\n",
    "cat_names = []\n",
    "super_cat_names = []\n",
    "super_cat_ids = {}\n",
    "super_cat_last_name = ''\n",
    "nr_super_cats = 0\n",
    "for cat_it in categories:\n",
    "    cat_names.append(cat_it['name'])\n",
    "    super_cat_name = cat_it['supercategory']\n",
    "    # Adding new supercat\n",
    "    if super_cat_name != super_cat_last_name:\n",
    "        super_cat_names.append(super_cat_name)\n",
    "        super_cat_ids[super_cat_name] = nr_super_cats\n",
    "        super_cat_last_name = super_cat_name\n",
    "        nr_super_cats += 1\n",
    "        \n",
    "# Count annotations\n",
    "cat_histogram = np.zeros(nr_cats,dtype=int)\n",
    "for ann in anns:\n",
    "    cat_histogram[ann['category_id']] += 1\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame({'Categories': cat_names, 'Number of annotations': cat_histogram})\n",
    "df = df.sort_values('Number of annotations', 0, False)\n",
    "\n",
    "# category labeling \n",
    "sorted_temp_df = df.sort_index()\n",
    "\n",
    "# background = 0 에 해당되는 label 추가 후 기존들을 모두 label + 1 로 설정\n",
    "sorted_df = pd.DataFrame([\"Backgroud\"], columns = [\"Categories\"])\n",
    "sorted_df = sorted_df.append(sorted_temp_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_names = list(sorted_df.Categories)\n",
    "\n",
    "def get_classname(classID, cats):\n",
    "    for i in range(len(cats)):\n",
    "        if cats[i]['id']==classID:\n",
    "            return cats[i]['name']\n",
    "    return \"None\"\n",
    "\n",
    "class CustomDataLoader(Dataset):\n",
    "    \"\"\"COCO format\"\"\"\n",
    "    def __init__(self, data_dir, mode = 'train', transform = None):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.coco = COCO(data_dir)\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        # dataset이 index되어 list처럼 동작\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "        image_infos = self.coco.loadImgs(image_id)[0]\n",
    "        \n",
    "        # cv2 를 활용하여 image 불러오기\n",
    "        images = cv2.imread(os.path.join(dataset_path, image_infos['file_name']))\n",
    "        images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        \n",
    "        if (self.mode in ('train', 'val')):\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=image_infos['id'])\n",
    "            anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "            # Load the categories in a variable\n",
    "            cat_ids = self.coco.getCatIds()\n",
    "            cats = self.coco.loadCats(cat_ids)\n",
    "\n",
    "            # masks : size가 (height x width)인 2D\n",
    "            # 각각의 pixel 값에는 \"category id + 1\" 할당\n",
    "            # Background = 0\n",
    "            masks = np.zeros((image_infos[\"height\"], image_infos[\"width\"]))\n",
    "            # Unknown = 1, General trash = 2, ... , Cigarette = 11\n",
    "            for i in range(len(anns)):\n",
    "                className = get_classname(anns[i]['category_id'], cats)\n",
    "                pixel_value = category_names.index(className)\n",
    "                masks = np.maximum(self.coco.annToMask(anns[i])*pixel_value, masks)\n",
    "            masks = masks.astype(np.float32)\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images, mask=masks)\n",
    "                images = transformed[\"image\"]\n",
    "                masks = transformed[\"mask\"]\n",
    "            \n",
    "            return images, masks\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images)\n",
    "                images = transformed[\"image\"]\n",
    "            \n",
    "            return images, image_infos\n",
    "    \n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        # 전체 dataset의 size를 return\n",
    "        return len(self.coco.getImgIds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if CFG.apex:\n",
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG  \n",
    "# ====================================================\n",
    "class CFG:\n",
    "    debug=False\n",
    "    img_size=512\n",
    "    max_len=275\n",
    "    print_freq=1000\n",
    "    num_workers=4\n",
    "    model_name='timm-efficientnet-b5' #['timm-efficientnet-b4', 'tf_efficientnet_b0_ns']\n",
    "    size=512 # [512, 1024]\n",
    "    freeze_epo = 0\n",
    "    warmup_epo = 1\n",
    "    cosine_epo = 39 #14 #19\n",
    "    warmup_factor=10\n",
    "    scheduler='GradualWarmupSchedulerV2' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts', 'GradualWarmupSchedulerV2', 'get_linear_schedule_with_warmup']\n",
    "    epochs=freeze_epo + warmup_epo + cosine_epo # not to exceed 9h #[1, 5, 10]\n",
    "    factor=0.2 # ReduceLROnPlateau\n",
    "    patience=4 # ReduceLROnPlateau\n",
    "    eps=1e-6 # ReduceLROnPlateau\n",
    "    T_max=4 # CosineAnnealingLR\n",
    "    T_0=4 # CosineAnnealingWarmRestarts\n",
    "    encoder_lr=3e-5 #[1e-4, 3e-5]\n",
    "    min_lr=1e-6\n",
    "    batch_size=32 + 0 #[64, 256 + 128, 512, 1024, 512 + 256 + 128, 2048]\n",
    "    weight_decay=1e-6\n",
    "    gradient_accumulation_steps=1\n",
    "    max_grad_norm=5\n",
    "    dropout=0.5\n",
    "    seed=42\n",
    "    smoothing=0.05\n",
    "    n_fold=5\n",
    "    trn_fold=[0]\n",
    "    trn_fold=[0, 1, 2, 3, 4] # [0, 1, 2, 3, 4]\n",
    "    train=True\n",
    "    apex=False\n",
    "    log_day='0504'\n",
    "    model_type=model_name\n",
    "    version='v1-1'\n",
    "    load_state=False\n",
    "    cutmix=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import sys\n",
    "#sys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import torchvision.models as models\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "# from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from albumentations import (\n",
    "    Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n",
    "    RandomBrightness, RandomContrast, RandomBrightnessContrast, Rotate, ShiftScaleRotate, Cutout, \n",
    "    IAAAdditiveGaussianNoise, Transpose, Blur, GaussNoise, MotionBlur, MedianBlur, OpticalDistortion, ElasticTransform, \n",
    "    GridDistortion, IAAPiecewiseAffine, CLAHE, IAASharpen, IAAEmboss, HueSaturationValue, ToGray, JpegCompression\n",
    "    )\n",
    "\n",
    "# train.json / validation.json / test.json 디렉토리 설정\n",
    "test_path = dataset_path + '/test.json'\n",
    "\n",
    "# collate_fn needs for batch\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "test_transform = A.Compose([\n",
    "                            A.Normalize(\n",
    "                                mean=(0.485, 0.456, 0.406),\n",
    "                                std=(0.229, 0.224, 0.225), max_pixel_value=255.0, p=1.0\n",
    "                            ),    \n",
    "                    ToTensorV2(transpose_mask=False)\n",
    "        ])\n",
    "\n",
    "\n",
    "# test dataset\n",
    "test_dataset = CustomDataLoader(data_dir=test_path, mode='test', transform=test_transform)\n",
    "\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                         batch_size=CFG.batch_size,\n",
    "                                          num_workers=CFG.num_workers,\n",
    "                                          pin_memory=True,\n",
    "                                          shuffle=False,\n",
    "                                          collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import scipy\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from scipy import ndimage\n",
    "from tqdm import tqdm\n",
    "from math import ceil\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pydensecrf.densecrf as dcrf\n",
    "from pydensecrf.utils import unary_from_softmax, create_pairwise_bilateral\n",
    "\n",
    "'''\n",
    "# Default Values are\n",
    "apperance_kernel = [8, 164, 100] # PairwiseBilateral [sxy, srgb, compat]  \n",
    "spatial_kernel = [3, 10]         # PairwiseGaussian  [sxy, compat] \n",
    "\n",
    "# or if you want to to specify seprately for each XY direction and RGB color channel then\n",
    "\n",
    "apperance_kernel = [(1.5, 1.5), (64, 64, 64), 100] # PairwiseBilateral [sxy, srgb, compat]  \n",
    "spatial_kernel = [(0.5, 0.5), 10]                  # PairwiseGaussian  [sxy, compat] \n",
    "'''\n",
    "# https://www.programcreek.com/python/example/106424/pydensecrf.densecrf.DenseCRF2D\n",
    "h, w = 512, 512\n",
    "def dense_crf(probs, img=None, n_classes=12, n_iters=10, scale_factor=1):\n",
    "    c,h,w = probs.shape\n",
    "    \n",
    "    if img is not None:\n",
    "        assert(img.shape[1:3] == (h, w))\n",
    "        img = np.transpose(img,(1,2,0)).copy(order='C')\n",
    "        img = np.uint8(255 * img)\n",
    "\n",
    "    d = dcrf.DenseCRF2D(w, h, n_classes) # Define DenseCRF model.\n",
    "\n",
    "    unary = unary_from_softmax(probs)\n",
    "    unary = np.ascontiguousarray(unary)\n",
    "    d.setUnaryEnergy(unary)\n",
    "    d.addPairwiseGaussian(sxy=(3,3), compat=10)\n",
    "    d.addPairwiseBilateral(sxy=10, srgb=5, rgbim=np.copy(img), compat=10)\n",
    "    Q = d.inference(n_iters)\n",
    "\n",
    "    preds = np.array(Q, dtype=np.float32).reshape((n_classes, h, w))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                     std = [ 1/0.229, 1/0.224, 1/0.225 ]),\n",
    "                                transforms.Normalize(mean = [ -0.485, -0.456, -0.406 ],\n",
    "                                                     std = [ 1., 1., 1. ]),\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ttach as tta\n",
    "\n",
    "transforms = tta.Compose(\n",
    "    [\n",
    "        tta.VerticalFlip(),\n",
    "        tta.Rotate90(angles=[0, 180, 270, 360]),\n",
    "        tta.Scale(scales=[0.75, 1, 1.25, 1.5])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG  \n",
    "# ====================================================\n",
    "class CFG:\n",
    "    debug=False\n",
    "    img_size=512\n",
    "    max_len=275\n",
    "    print_freq=1000\n",
    "    num_workers=4\n",
    "    model_name='timm-efficientnet-b5' #['timm-efficientnet-b4', 'tf_efficientnet_b0_ns']\n",
    "    size=512 # [512, 1024]\n",
    "    freeze_epo = 0\n",
    "    warmup_epo = 1\n",
    "    cosine_epo = 39 #14 #19\n",
    "    warmup_factor=10\n",
    "    scheduler='GradualWarmupSchedulerV2' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts', 'GradualWarmupSchedulerV2', 'get_linear_schedule_with_warmup']\n",
    "    epochs=freeze_epo + warmup_epo + cosine_epo # not to exceed 9h #[1, 5, 10]\n",
    "    factor=0.2 # ReduceLROnPlateau\n",
    "    patience=4 # ReduceLROnPlateau\n",
    "    eps=1e-6 # ReduceLROnPlateau\n",
    "    T_max=4 # CosineAnnealingLR\n",
    "    T_0=4 # CosineAnnealingWarmRestarts\n",
    "    encoder_lr=3e-5 #[1e-4, 3e-5]\n",
    "    min_lr=1e-6\n",
    "    batch_size=24 + 0 #[64, 256 + 128, 512, 1024, 512 + 256 + 128, 2048]\n",
    "    weight_decay=1e-6\n",
    "    gradient_accumulation_steps=1\n",
    "    max_grad_norm=5\n",
    "    dropout=0.5\n",
    "    seed=42\n",
    "    smoothing=0.05\n",
    "    n_fold=5\n",
    "    trn_fold=[0]\n",
    "    trn_fold=[0, 1, 2, 3, 4] # [0, 1, 2, 3, 4]\n",
    "    train=True\n",
    "    apex=False\n",
    "    log_day='0505'\n",
    "    model_type=model_name\n",
    "    version='v1-1'\n",
    "    load_state=False\n",
    "    cutmix=False\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, model_name='timm-efficientnet-b5', pretrained=False):\n",
    "        super().__init__()        \n",
    "        self.encoder = smp.FPN(encoder_name=model_name, encoder_weights=\"noisy-student\", classes=12) # [imagenet, noisy-student]\n",
    "    \n",
    "    #@autocast()\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "    \n",
    "models = []\n",
    "for fold in range(5): \n",
    "    model_path = f'./submission{CFG.log_day}_d{CFG.dropout}_s{CFG.seed}_{CFG.model_name}_{CFG.version}_fold{fold}_best.pth'\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model = Encoder(CFG.model_name, pretrained=False)\n",
    "    model.load_state_dict(checkpoint['encoder'])\n",
    "    tta_model = tta.SegmentationTTAWrapper(model, transforms)\n",
    "    models += [tta_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG  \n",
    "# ====================================================\n",
    "class CFG:\n",
    "    debug=False\n",
    "    img_size=512\n",
    "    max_len=275\n",
    "    print_freq=1000\n",
    "    num_workers=4\n",
    "    model_name='se_resnext50_32x4d' #['timm-efficientnet-b4', 'se_resnext50_32x4d', 'mobilenet_v2']\n",
    "    size=512 # [512, 1024]\n",
    "    freeze_epo = 0\n",
    "    warmup_epo = 1\n",
    "    cosine_epo = 39 #14 #19\n",
    "    warmup_factor=10\n",
    "    scheduler='GradualWarmupSchedulerV2' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts', 'GradualWarmupSchedulerV2', 'get_linear_schedule_with_warmup']\n",
    "    epochs=freeze_epo + warmup_epo + cosine_epo # not to exceed 9h #[1, 5, 10]\n",
    "    factor=0.2 # ReduceLROnPlateau\n",
    "    patience=4 # ReduceLROnPlateau\n",
    "    eps=1e-6 # ReduceLROnPlateau\n",
    "    T_max=4 # CosineAnnealingLR\n",
    "    T_0=4 # CosineAnnealingWarmRestarts\n",
    "    encoder_lr=3e-5 #[1e-4, 3e-5]\n",
    "    min_lr=1e-6\n",
    "    batch_size=24 + 0 #[64, 256 + 128, 512, 1024, 512 + 256 + 128, 2048]\n",
    "    weight_decay=1e-6\n",
    "    gradient_accumulation_steps=1\n",
    "    max_grad_norm=5\n",
    "    dropout=0.5\n",
    "    seed=42\n",
    "    smoothing=0.05\n",
    "    n_fold=5\n",
    "    trn_fold=[0]\n",
    "    trn_fold=[0, 1, 2, 3, 4] # [0, 1, 2, 3, 4]\n",
    "    train=True\n",
    "    apex=False\n",
    "    log_day='0504'\n",
    "    model_type=model_name\n",
    "    version='v1-1'\n",
    "    load_state=False\n",
    "    cutmix=False\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, model_name='se_resnext50_32x4d', pretrained=False):\n",
    "        super().__init__()        \n",
    "        self.encoder = smp.DeepLabV3Plus(encoder_name=model_name, encoder_weights=\"imagenet\", classes=12) # [imagenet, noisy-student]\n",
    "    \n",
    "    # @autocast()\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "    \n",
    "model_name = 'se_resnext50_32x4d'\n",
    "for fold in range(5): \n",
    "    model_path = f'./submission{CFG.log_day}_d{CFG.dropout}_s{CFG.seed}_{CFG.model_name}_{CFG.version}_fold{fold}_best.pth'\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model = Encoder(model_name, pretrained=False)\n",
    "    model.load_state_dict(checkpoint['encoder'])\n",
    "    tta_model = tta.SegmentationTTAWrapper(model, transforms)\n",
    "    models += [tta_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def test(models, data_loader, device):\n",
    "    size = 256\n",
    "    transform = A.Compose([A.Resize(256, 256)])\n",
    "    print('Start prediction.')\n",
    "    \n",
    "    file_name_list = []\n",
    "    preds_array = np.empty((0, size*size), dtype=np.long)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for step, (imgs, image_infos) in enumerate(test_loader):\n",
    "\n",
    "            # inference (512 x 512)\n",
    "            for n, model in enumerate(models): \n",
    "                model = model.to(device)\n",
    "                model.eval()\n",
    "                if n == 0: \n",
    "                    outs = model(torch.stack(imgs).to(device))\n",
    "                else: \n",
    "                    outs += model(torch.stack(imgs).to(device))\n",
    "\n",
    "                    \n",
    "            probs_array = []\n",
    "            for image, prob in zip(imgs, outs):\n",
    "                prob = F.softmax(prob, dim=0)                    \n",
    "                prob = dense_crf(img=np.around(invTrans(image).cpu().numpy()).astype(float), probs=prob.cpu().numpy())\n",
    "                probs_array += [np.argmax(prob, axis=0)]\n",
    "                    \n",
    "            oms = np.array(probs_array)\n",
    "            \n",
    "            # oms = np.argmax(outs.squeeze(), axis=1)            \n",
    "            # resize (256 x 256)\n",
    "            temp_mask = []\n",
    "            for img, mask in zip(np.stack(imgs), oms):\n",
    "                transformed = transform(image=img, mask=mask)\n",
    "                mask = transformed['mask']\n",
    "                temp_mask.append(mask)\n",
    "\n",
    "            oms = np.array(temp_mask)\n",
    "            oms = np.around(oms.reshape([oms.shape[0], size*size])).astype(int)\n",
    "            preds_array = np.vstack((preds_array, oms))\n",
    "            file_name_list.append([i['file_name'] for i in image_infos])\n",
    "            \n",
    "    print(\"End prediction.\")\n",
    "    file_names = [y for x in file_name_list for y in x]\n",
    "    \n",
    "    return file_names, preds_array\n",
    "\n",
    "# sample_submisson.csv 열기\n",
    "submission = pd.read_csv('./submission/sample_submission.csv', index_col=None)\n",
    "\n",
    "# test set에 대한 prediction\n",
    "file_names, preds = test(models, test_loader, device)\n",
    "\n",
    "# PredictionString 대입\n",
    "for file_name, string in zip(file_names, preds):\n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "# submission.csv로 저장  # 0.3552\t\n",
    "submission.to_csv(\"./submission/0505_EfficientFPNB5_5FOLD_FLIP_CRF2_DEEPLABV3PLUS_TTA3.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36] *",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
